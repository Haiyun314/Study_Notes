[Source](https://www.icourse163.org/course/XHUN-1472829184)

- [RL and combinatorial optimization](#rl-and-combinatorial-optimization)
- [RL + LLM](#rl--llm)

## RL and combinatorial optimization
### Background
- Traveling Salesman Problem (TSP): Find the shortest route that visits all cities once and returns to the start.

- Job Shop Scheduling Problem (JSSP): Assign jobs to machines in a sequence that minimizes total completion time or delays.

- Chip Design: Optimize the placement and routing of components on a chip to reduce area, power use, and signal delays.

- Unit Commitment (UC): Decide which power units to turn on/off over time to meet demand at minimal cost while satisfying operational constraints.

definition: 
<img src='./images/Screenshot 2025-05-12 at 07.38.30.png' width= '500'/>

Traditional Solutions : 
- Brute-force search: Examines all possible solutions; accurate but extremely slow for large problems due to factorial complexity.

- Dynamic programming: Solves problems by breaking them into overlapping subproblems; more efficient by storing and reusing results.

- Branch and bound: Explores the solution space selectively, pruning branches that can't yield better results to save computation.

- Evolutionary algorithms: Use mechanisms like selection, mutation, and crossover to evolve solutions over time; good for complex, non-linear problems.

- Pros: Can find accurate or near-optimal solutions.

- Cons: Often require high computational time and memory.

### RL solution
TSP
<img src='./images/Screenshot 2025-05-12 at 08.07.46.png' width= '500'/>

### challenge
- generalization ability of the solution: augmented dataset, emsemble learning
<img src='./images/Screenshot 2025-05-12 at 08.19.22.png' width= '500'/>

- Multi-agent optimization uses multiple agents to cooperatively or competitively solve problems like TSP, balancing time (e.g. travel duration) and cost (e.g. fuel, tolls). Agents explore different routes in parallel, improving solution quality and efficiency.
<img src='./images/Screenshot 2025-05-12 at 09.03.06.png' width= '500'/>


## RL + LLM
### RLHF 
- reinforcement learning with feedback : align AI behavior with human values and preferences. 
- *** Reward *** : Annotators rank the responses generated by the large model for a given prompt.
- <img src='./images/Screenshot 2025-05-11 at 10.30.04.png' width ='500'/>

- ***PPO*** : Proximal Policy Optimization
- <img src='./images/Screenshot 2025-05-11 at 10.08.01.png' width= '500'/>

- ***DPO*** : Direct Preference Optimization
- <img src='./images/Screenshot 2025-05-11 at 10.31.17.png' width = '500'/>

- ***SimPO*** : Simpler Preference Optimization
- <img src='./images/Screenshot 2025-05-11 at 10.11.17.png' width = '500'/>

- ***KTO*** : Kahneman-Tversky Optimization
- <img src='./images/Screenshot 2025-05-11 at 10.10.57.png' width= '500'/>

